{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reproduce_float32_issue.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP0z3GIgmLdh7fsog3NB/0f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","\n","print(\"Current version\", torch.__version__)\n","print(\"Problem was detected on 1.10.0+cu111\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmXB8TXvVTM_","executionInfo":{"status":"ok","timestamp":1644340210019,"user_tz":-180,"elapsed":254,"user":{"displayName":"Emil Bogomolov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04442002603025397676"}},"outputId":"1b43eaac-aaad-4032-b691-c45d7e1c5e0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current version 1.10.0+cu111\n","Problem was detected on 1.10.0+cu111\n"]}]},{"cell_type":"code","source":["class FastConv(object):\n","\n","  @staticmethod\n","  def forward(x, w, b, conv_param):\n","    # print(x.shape, w.shape, b.shape, conv_param)\n","    N, C, H, W = x.shape\n","    F, _, HH, WW = w.shape\n","    stride, pad = conv_param['stride'], conv_param['pad']\n","    layer = torch.nn.Conv2d(C, F, (HH, WW), stride=stride, padding=pad)\n","    layer.weight = torch.nn.Parameter(w)\n","    layer.bias = torch.nn.Parameter(b)\n","    tx = x.detach()\n","    tx.requires_grad = True\n","    out = layer(tx)\n","    cache = (x, w, b, conv_param, tx, out, layer)\n","    return out, cache\n","\n","  @staticmethod\n","  def backward(dout, cache):\n","    try:\n","      x, _, _, _, tx, out, layer = cache\n","      out.backward(dout)\n","      dx = tx.grad.detach()\n","      dw = layer.weight.grad.detach()\n","      db = layer.bias.grad.detach()\n","      layer.weight.grad = layer.bias.grad = None\n","    except RuntimeError:\n","      dx, dw, db = torch.zeros_like(tx), torch.zeros_like(layer.weight), torch.zeros_like(layer.bias)\n","    return dx, dw, db"],"metadata":{"id":"4nk_wk7YZVrm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cpu'\n","num_inputs = 2\n","input_dims = (3, 16, 16)\n","next_filt = 16\n","\n","batchnorm = True\n","dtype = torch.float32\n","\n","kernel_size = 3\n","bn_param = {'mode': 'train'}\n","# stride and padding preserve output spatial size\n","conv_param = {'stride': 1, 'pad': (kernel_size - 1) // 2}\n","\n","\n","x = torch.randn(num_inputs, *input_dims, dtype=dtype, device=device)\n","\n","gamma = torch.ones(input_dims[0], device=device, dtype=dtype)\n","beta = torch.zeros(input_dims[0], device=device, dtype=dtype)\n","\n","Weight = torch.randn(next_filt, input_dims[0], kernel_size, kernel_size, dtype=dtype, device=device)\n","b = torch.zeros(next_filt, dtype=dtype, device=device)\n","\n","N, C, H, W = x.shape\n","\n","## PyTorch BN2d\n","try:\n","  out = torch.nn.BatchNorm2d(C, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=device, dtype=dtype).forward(x)\n","\n","  out_bn_2d, _ = FastConv.forward(out, Weight, b, conv_param)\n","except Exception as e:\n","  print(e)\n","\n","## Pytorch BN1d\n","try:\n","  ch_view = x.transpose(1,2).transpose(2,3).reshape(N * H * W, C) \n","  out = torch.nn.BatchNorm1d(C, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=device, dtype=dtype).forward(ch_view)\n","  out = out.reshape(N, H, W, C).transpose(2,3).transpose(1,2)\n","\n","  out_bn_1d, _ = FastConv.forward(out, Weight, b, conv_param)\n","except Exception as e:\n","  print(e)\n","\n","print(\"BN1d vs BN2d\", torch.norm(out_bn_1d - out_bn_2d).item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0my3MNBXAye","executionInfo":{"status":"ok","timestamp":1644340231173,"user_tz":-180,"elapsed":186,"user":{"displayName":"Emil Bogomolov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04442002603025397676"}},"outputId":"b2340143-2bd0-42b8-ed4f-de7e71068695"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BN1d vs BN2d 8.046893344726413e-05\n"]}]},{"cell_type":"code","source":["!pip3 install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html -U\n","\n","import torch\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":765},"id":"Nn-9mDXNx1-Y","executionInfo":{"status":"ok","timestamp":1644432962398,"user_tz":-180,"elapsed":218947,"user":{"displayName":"Emil Bogomolov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04442002603025397676"}},"outputId":"0e25543f-6035-4108-87c5-b55055d06f8d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.2+cu111)\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/nightly/cu111/torch-1.12.0.dev20220209%2Bcu111-cp37-cp37m-linux_x86_64.whl (1922.9 MB)\n","\u001b[K     |█████████████▉                  | 834.1 MB 1.5 MB/s eta 0:12:06tcmalloc: large alloc 1147494400 bytes == 0x562593bca000 @  0x7f517dab3615 0x56255969b3bc 0x56255977c18a 0x56255969e1cd 0x562559790b3d 0x562559712458 0x56255970d02f 0x56255969faba 0x5625597122c0 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x56255969ff19 0x5625596e3a79 0x56255969eb32 0x5625597121dd 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f 0x56255969faba 0x56255970deae 0x56255969f9da 0x56255970e108 0x56255970d02f\n","\u001b[K     |█████████████████▋              | 1055.7 MB 1.6 MB/s eta 0:09:11tcmalloc: large alloc 1434370048 bytes == 0x5625d8220000 @  0x7f517dab3615 0x56255969b3bc 0x56255977c18a 0x56255969e1cd 0x562559790b3d 0x562559712458 0x56255970d02f 0x56255969faba 0x5625597122c0 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x56255969ff19 0x5625596e3a79 0x56255969eb32 0x5625597121dd 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f 0x56255969faba 0x56255970deae 0x56255969f9da 0x56255970e108 0x56255970d02f\n","\u001b[K     |██████████████████████▎         | 1336.2 MB 1.5 MB/s eta 0:06:21tcmalloc: large alloc 1792966656 bytes == 0x56255d052000 @  0x7f517dab3615 0x56255969b3bc 0x56255977c18a 0x56255969e1cd 0x562559790b3d 0x562559712458 0x56255970d02f 0x56255969faba 0x5625597122c0 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x56255969ff19 0x5625596e3a79 0x56255969eb32 0x5625597121dd 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f 0x56255969faba 0x56255970deae 0x56255969f9da 0x56255970e108 0x56255970d02f\n","\u001b[K     |████████████████████████████▏   | 1691.1 MB 1.4 MB/s eta 0:02:41tcmalloc: large alloc 2241208320 bytes == 0x5625c7e3a000 @  0x7f517dab3615 0x56255969b3bc 0x56255977c18a 0x56255969e1cd 0x562559790b3d 0x562559712458 0x56255970d02f 0x56255969faba 0x5625597122c0 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x562559791986 0x56255970e350 0x56255969ff19 0x5625596e3a79 0x56255969eb32 0x5625597121dd 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f 0x56255969faba 0x56255970deae 0x56255969f9da 0x56255970e108 0x56255970d02f\n","\u001b[K     |████████████████████████████████| 1922.9 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 1922916352 bytes == 0x56264d79c000 @  0x7f517dab21e7 0x5625596d15d7 0x56255969b3bc 0x56255977c18a 0x56255969e1cd 0x562559790b3d 0x562559712458 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255969f9da 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f\n","tcmalloc: large alloc 2403647488 bytes == 0x5626c0172000 @  0x7f517dab3615 0x56255969b3bc 0x56255977c18a 0x56255969e1cd 0x562559790b3d 0x562559712458 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970e108 0x56255969f9da 0x56255970e108 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f 0x56255969faba 0x56255970ecd4 0x56255970d02f 0x5625596a0151\n","\u001b[K     |████████████████████████████████| 1922.9 MB 5.4 kB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.3)\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/nightly/cu111/torchvision-0.13.0.dev20220209%2Bcu111-cp37-cp37m-linux_x86_64.whl (22.4 MB)\n","\u001b[K     |████████████████████████████████| 22.4 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.2+cu111\n","    Uninstalling torch-1.10.2+cu111:\n","      Successfully uninstalled torch-1.10.2+cu111\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.3\n","    Uninstalling torchvision-0.11.3:\n","      Successfully uninstalled torchvision-0.11.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.12.0.dev20220209+cu111 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.12.0.dev20220209+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.12.0.dev20220209+cu111 torchvision-0.13.0.dev20220209+cu111\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1.10.2+cu111\n"]}]},{"cell_type":"code","source":["import torch\n","print(torch.__version__)\n","\n","class FastConv(object):\n","  @staticmethod\n","  def forward(x, w, b, conv_param):\n","    # print(x.shape, w.shape, b.shape, conv_param)\n","    N, C, H, W = x.shape\n","    F, _, HH, WW = w.shape\n","    stride, pad = conv_param['stride'], conv_param['pad']\n","    layer = torch.nn.Conv2d(C, F, (HH, WW), stride=stride, padding=pad)\n","    layer.weight = torch.nn.Parameter(w)\n","    layer.bias = torch.nn.Parameter(b)\n","    tx = x.detach()\n","    tx.requires_grad = True\n","    out = layer(tx)\n","    cache = (x, w, b, conv_param, tx, out, layer)\n","    return out, cache\n","\n","  @staticmethod\n","  def backward(dout, cache):\n","    try:\n","      x, _, _, _, tx, out, layer = cache\n","      out.backward(dout)\n","      dx = tx.grad.detach()\n","      dw = layer.weight.grad.detach()\n","      db = layer.bias.grad.detach()\n","      layer.weight.grad = layer.bias.grad = None\n","    except RuntimeError:\n","      dx, dw, db = torch.zeros_like(tx), torch.zeros_like(layer.weight), torch.zeros_like(layer.bias)\n","    return dx, dw, db\n","\n","\n","device = 'cuda'\n","num_inputs = 2\n","input_dims = (3, 16, 16)\n","next_filt = 16\n","\n","batchnorm = True\n","dtype = torch.float32\n","\n","kernel_size = 3\n","bn_param = {'mode': 'train'}\n","# stride and padding preserve output spatial size\n","conv_param = {'stride': 1, 'pad': (kernel_size - 1) // 2}\n","\n","x = torch.randn(num_inputs, *input_dims, dtype=dtype, device=device)\n","\n","gamma = torch.ones(input_dims[0], device=device, dtype=dtype)\n","beta = torch.zeros(input_dims[0], device=device, dtype=dtype)\n","\n","Weight = torch.randn(next_filt, input_dims[0], kernel_size, kernel_size, dtype=dtype, device=device)\n","b = torch.zeros(next_filt, dtype=dtype, device=device)\n","\n","N, C, H, W = x.shape\n","\n","## PyTorch BN2d\n","out = torch.nn.BatchNorm2d(C, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=device, dtype=dtype).forward(x)\n","out_bn_2d, _ = FastConv.forward(out, Weight, b, conv_param)\n","print(out_bn_2d.shape)\n","# > torch.Size([2, 16, 16, 16])\n","\n","## Pytorch BN1d\n","ch_view = x.transpose(1,2).transpose(2,3).reshape(N * H * W, C) \n","out = torch.nn.BatchNorm1d(C, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=device, dtype=dtype).forward(ch_view)\n","out = out.reshape(N, H, W, C).transpose(2,3).transpose(1,2)\n","out_bn_1d, _ = FastConv.forward(out, Weight, b, conv_param)\n","print(out_bn_1d.shape)\n","# > torch.Size([2, 16, 16, 16])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lX-zbpfkxhPh","executionInfo":{"status":"ok","timestamp":1644433008563,"user_tz":-180,"elapsed":7367,"user":{"displayName":"Emil Bogomolov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04442002603025397676"}},"outputId":"957779a3-fade-4e27-fc22-7409e7ddeb2a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1.12.0.dev20220209+cu111\n","torch.Size([2, 16, 16, 16])\n","torch.Size([2, 16, 16, 16])\n"]}]}]}